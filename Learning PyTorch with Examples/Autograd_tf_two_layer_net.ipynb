{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"tf_two_layer_net.ipynb","version":"0.3.2","views":{},"default_view":{},"provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"LnBkSt0T6Iit","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["%matplotlib inline"],"execution_count":0,"outputs":[]},{"metadata":{"id":"HZJiCAMU6Ii0","colab_type":"text"},"cell_type":"markdown","source":["\n","TensorFlow: Static Graphs\n","-------------------------\n","\n","A fully-connected ReLU network with one hidden layer and no biases, trained to\n","predict y from x by minimizing squared Euclidean distance.\n","\n","This implementation uses basic TensorFlow operations to set up a computational\n","graph, then executes the graph many times to actually train the network.\n","\n","One of the main differences between TensorFlow and PyTorch is that TensorFlow\n","uses static computational graphs while PyTorch uses dynamic computational\n","graphs.\n","\n","In TensorFlow we first set up the computational graph, then execute the same\n","graph many times.\n","\n"]},{"metadata":{"id":"cwdm6XkF6c5s","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"output_extras":[{"item_id":4}],"base_uri":"https://localhost:8080/","height":8517},"outputId":"0438a589-d9f4-466c-97c4-27f1b2aa35cc","executionInfo":{"status":"ok","timestamp":1522850875133,"user_tz":-480,"elapsed":2278,"user":{"displayName":"Ting-Hao Chen","photoUrl":"//lh5.googleusercontent.com/-AqNMIr4i_vY/AAAAAAAAAAI/AAAAAAACYZM/s73Q8MSTaOY/s50-c-k-no/photo.jpg","userId":"102252651198589151727"}}},"cell_type":"code","source":["import tensorflow as tf\n","import numpy as np\n","\n","# First we set up the computational graph:\n","\n","# N: batch size, D_in: input dim, H: hidden dim, D_out: output dim\n","N, D_in, H, D_out = 64, 1000, 100, 10\n","\n","# Create placeholders for the input and target data.\n","# These will be filled with real data when we execute the graph.\n","x = tf.placeholder(tf.float32, shape=(None, D_in))\n","y = tf.placeholder(tf.float32, shape=(None, D_out))\n","\n","# Create Variables for the weights and initialize them with random data.\n","# A TensorFlow Variable persists its value across executions of the graph.\n","w1 = tf.Variable(tf.random_normal((D_in, H)))\n","w2 = tf.Variable(tf.random_normal((H, D_out)))\n","\n","# Forward pass: Compute the predicted y using operations on TensorFlow Tensors.\n","# Note that this code does not actually perform any numeric operations.\n","# It merely sets up the computational graph that will later execute.\n","h = tf.matmul(x, w1)\n","h_relu = tf.maximum(h, tf.zeros(1))\n","y_pred = tf.matmul(h_relu, w2)\n","\n","# Compute loss using operations on TensorFlow Tensors\n","loss = tf.reduce_sum((y - y_pred) ** 2.0)\n","\n","# Compute gradient of the loss with respect to w1 and w2.\n","grad_w1, grad_w2 = tf.gradients(loss, [w1, w2])\n","\n","# Update the weights using gradient descent. To actually update the weights\n","# we need to evaluate new_w1 and new_w2 when executing the graph. Note that \n","# in TensorFlow the act of updating the value of the weights is part of the \n","# computational graph. In Python this happens outside the computational graph.\n","learning_rate = 1e-6\n","new_w1 = w1.assign(w1 - learning_rate * grad_w1)\n","new_w2 = w2.assign(w2 - learning_rate * grad_w2)\n","\n","# Now we have built our computational graph, so we enter a TensorFlow session\n","# to actually execute the graph.\n","with tf.Session() as sess:\n","    # Run the graph once to initialize the Variable w1 and w2.\n","    sess.run(tf.global_variables_initializer())\n","    \n","    # Create numpy arrays holding the actual data for the inputs x and \n","    # targets y.\n","    x_value = np.random.randn(N, D_in)\n","    y_value = np.random.randn(N, D_out)\n","    \n","    for _ in range(500):\n","        # Execute the graph many times. Each time it execure we want to bind.\n","        # x_value to x and y_value to y, specified with the feed_dict argument.\n","        # Each times we execure the graph we want to compute the values for loss,\n","        # new_w1 and new_w2. The values of these Tensors are returned as numpy\n","        # array.\n","        loss_value, _, _, = sess.run([loss, new_w1, new_w2],\n","                                     feed_dict={x: x_value, y: y_value})\n","        print(loss_value)"],"execution_count":4,"outputs":[{"output_type":"stream","text":["35269136.0\n","31126378.0\n","28563530.0\n","24069556.0\n","17564582.0\n","11244671.0\n","6649901.0\n","3916117.0\n","2433987.8\n","1642084.5\n","1198964.8\n","930652.25\n","752766.75\n","625063.9\n","527808.5\n","450801.38\n","388186.75\n","336317.6\n","292914.6\n","256314.45\n","225198.78\n","198556.88\n","175639.25\n","155847.81\n","138672.12\n","123718.39\n","110650.12\n","99186.94\n","89100.19\n","80195.91\n","72314.266\n","65317.727\n","59091.117\n","53540.63\n","48580.9\n","44140.246\n","40154.832\n","36572.43\n","33348.676\n","30446.52\n","27829.887\n","25469.746\n","23332.432\n","21394.152\n","19634.305\n","18034.406\n","16577.959\n","15251.022\n","14042.302\n","12938.73\n","11929.872\n","11007.061\n","10162.078\n","9387.184\n","8676.488\n","8023.966\n","7424.686\n","6873.7305\n","6367.1714\n","5900.7817\n","5471.3086\n","5075.2373\n","4710.012\n","4372.9346\n","4061.6575\n","3773.9932\n","3508.0369\n","3262.0608\n","3034.462\n","2823.767\n","2628.6067\n","2447.6963\n","2280.02\n","2124.4448\n","1980.1294\n","1846.1383\n","1721.7529\n","1606.1918\n","1498.8269\n","1398.9661\n","1306.0951\n","1219.6857\n","1139.3041\n","1064.4677\n","994.7883\n","929.87555\n","869.3976\n","813.0355\n","760.70483\n","711.9252\n","666.42346\n","623.973\n","584.32825\n","547.32275\n","512.773\n","480.4791\n","450.30548\n","422.10764\n","395.74847\n","371.10004\n","348.05286\n","326.4908\n","306.31052\n","287.42892\n","269.74927\n","253.19733\n","237.69904\n","223.18207\n","209.58282\n","196.84627\n","184.90431\n","173.71428\n","163.22052\n","153.38472\n","144.16006\n","135.50746\n","127.39563\n","119.781586\n","112.634575\n","105.92704\n","99.63102\n","93.71846\n","88.1682\n","82.95942\n","78.06664\n","73.46655\n","69.146095\n","65.08745\n","61.271183\n","57.688904\n","54.319256\n","51.152958\n","48.175747\n","45.375416\n","42.742336\n","40.26415\n","37.934223\n","35.741844\n","33.68139\n","31.741726\n","29.914858\n","28.196365\n","26.579288\n","25.056501\n","23.624058\n","22.27362\n","21.003658\n","19.805965\n","18.679928\n","17.618816\n","16.617458\n","15.676199\n","14.787654\n","13.950925\n","13.163509\n","12.4207\n","11.721173\n","11.061298\n","10.439675\n","9.8532095\n","9.300869\n","8.779917\n","8.287748\n","7.824082\n","7.3869677\n","6.974904\n","6.5859175\n","6.219495\n","5.8734145\n","5.5472956\n","5.2390966\n","4.948554\n","4.6746154\n","4.4154797\n","4.1711864\n","3.9404492\n","3.7233212\n","3.517752\n","3.323864\n","3.1411605\n","2.9682083\n","2.8048716\n","2.6511378\n","2.5055742\n","2.3679984\n","2.2383249\n","2.1156425\n","1.9999379\n","1.8906368\n","1.7875618\n","1.6901374\n","1.5980444\n","1.510814\n","1.4285216\n","1.3506608\n","1.2774105\n","1.2077366\n","1.1421169\n","1.0803094\n","1.0216613\n","0.9662097\n","0.9140604\n","0.8646278\n","0.8178271\n","0.7735667\n","0.7318503\n","0.6924386\n","0.65507627\n","0.6197528\n","0.5863947\n","0.55491453\n","0.5249502\n","0.49661148\n","0.4700372\n","0.44485947\n","0.4209372\n","0.39829823\n","0.37693536\n","0.3568055\n","0.33761916\n","0.31955662\n","0.3024472\n","0.28632665\n","0.27101165\n","0.2566138\n","0.24299106\n","0.22999062\n","0.21772166\n","0.20605819\n","0.19508927\n","0.1847798\n","0.17486802\n","0.16555464\n","0.15675898\n","0.14842083\n","0.14053635\n","0.13307089\n","0.12604083\n","0.119323224\n","0.11302322\n","0.10701208\n","0.101370454\n","0.09601549\n","0.09091587\n","0.08608574\n","0.0815402\n","0.07721623\n","0.0731392\n","0.06932609\n","0.06564052\n","0.062200617\n","0.058932036\n","0.05581408\n","0.052870255\n","0.050089978\n","0.047444172\n","0.04496756\n","0.042604964\n","0.040359482\n","0.038251262\n","0.036242194\n","0.03432946\n","0.032519743\n","0.030812638\n","0.02921596\n","0.027689049\n","0.02625459\n","0.024882076\n","0.023585098\n","0.02234641\n","0.021187922\n","0.020080375\n","0.019045848\n","0.018067345\n","0.017117951\n","0.01623026\n","0.015385998\n","0.014582302\n","0.013831741\n","0.013116318\n","0.012441864\n","0.011811365\n","0.011211348\n","0.010623061\n","0.010084366\n","0.009568528\n","0.009079264\n","0.008625848\n","0.008185523\n","0.007768588\n","0.0073735164\n","0.0070016296\n","0.0066555473\n","0.00632824\n","0.006010379\n","0.005714637\n","0.00543318\n","0.0051619885\n","0.004910142\n","0.004674217\n","0.0044451323\n","0.0042256336\n","0.0040180944\n","0.0038248193\n","0.0036416058\n","0.0034650262\n","0.0033049637\n","0.0031506775\n","0.0030044327\n","0.002865181\n","0.002730516\n","0.0026009516\n","0.002482475\n","0.002368685\n","0.0022604167\n","0.0021609084\n","0.0020613873\n","0.0019693659\n","0.001881909\n","0.0017983677\n","0.001720319\n","0.0016471826\n","0.0015779372\n","0.0015113254\n","0.0014495387\n","0.001388337\n","0.0013324711\n","0.0012767415\n","0.0012278087\n","0.0011789178\n","0.00113365\n","0.001087751\n","0.0010454471\n","0.0010033809\n","0.00096482795\n","0.0009269802\n","0.0008928617\n","0.0008598714\n","0.00082664983\n","0.0007958664\n","0.0007661147\n","0.0007400981\n","0.0007124281\n","0.0006869123\n","0.00066444464\n","0.0006409597\n","0.00061817747\n","0.0005979394\n","0.00057776074\n","0.00055816973\n","0.0005392033\n","0.0005217385\n","0.0005038411\n","0.00048690717\n","0.00047140408\n","0.00045658424\n","0.00044107475\n","0.0004271133\n","0.00041346246\n","0.00040000738\n","0.00038754422\n","0.0003758091\n","0.00036502077\n","0.00035414277\n","0.00034316906\n","0.0003336862\n","0.00032453742\n","0.00031431482\n","0.00030482127\n","0.00029588502\n","0.00028724142\n","0.00027937314\n","0.00027212474\n","0.0002637728\n","0.00025669148\n","0.00025019408\n","0.0002437577\n","0.00023671161\n","0.00023058317\n","0.00022432226\n","0.00021849631\n","0.00021307028\n","0.00020758368\n","0.00020177495\n","0.0001967266\n","0.00019153865\n","0.00018708801\n","0.00018205708\n","0.00017746523\n","0.00017363156\n","0.0001693447\n","0.00016547277\n","0.00016188723\n","0.00015839035\n","0.00015452765\n","0.00015104258\n","0.00014744407\n","0.00014392895\n","0.00014088383\n","0.00013757918\n","0.00013468598\n","0.00013117294\n","0.00012853726\n","0.00012591133\n","0.00012335213\n","0.00012068341\n","0.00011836839\n","0.00011552392\n","0.00011285623\n","0.00011045078\n","0.00010811993\n","0.000105703584\n","0.000103677405\n","0.00010174855\n","9.9732766e-05\n","9.774521e-05\n","9.586254e-05\n","9.402374e-05\n","9.224575e-05\n","9.0197216e-05\n","8.861765e-05\n","8.678143e-05\n","8.5360385e-05\n","8.3786246e-05\n","8.2125516e-05\n","8.058555e-05\n","7.90991e-05\n","7.756555e-05\n","7.587834e-05\n","7.428217e-05\n","7.281972e-05\n","7.205463e-05\n","7.095131e-05\n","6.98441e-05\n","6.8576126e-05\n","6.728327e-05\n","6.598356e-05\n","6.477952e-05\n","6.386246e-05\n","6.287083e-05\n","6.1720726e-05\n","6.080317e-05\n","5.973507e-05\n","5.8778336e-05\n","5.7820867e-05\n","5.6820543e-05\n","5.6056466e-05\n","5.5148976e-05\n","5.4398017e-05\n","5.355243e-05\n","5.256137e-05\n","5.1874686e-05\n","5.1150586e-05\n","5.025206e-05\n","4.9210954e-05\n","4.8513495e-05\n","4.7797428e-05\n","4.704832e-05\n","4.639335e-05\n","4.5676406e-05\n","4.5025186e-05\n","4.4510034e-05\n","4.3854237e-05\n","4.32461e-05\n","4.27372e-05\n","4.2166423e-05\n","4.1700732e-05\n","4.1104955e-05\n","4.054011e-05\n","4.006049e-05\n","3.9531318e-05\n","3.8998136e-05\n","3.8369733e-05\n","3.785576e-05\n","3.7298556e-05\n","3.690472e-05\n","3.6336824e-05\n","3.5983365e-05\n","3.549907e-05\n","3.512135e-05\n","3.4764922e-05\n","3.4298784e-05\n","3.3765875e-05\n","3.3368193e-05\n","3.3033037e-05\n","3.2797267e-05\n","3.2386593e-05\n","3.193182e-05\n","3.1611748e-05\n","3.125502e-05\n","3.092602e-05\n","3.0491537e-05\n","3.0182027e-05\n","2.987536e-05\n","2.9627525e-05\n","2.9290299e-05\n","2.8882876e-05\n","2.857532e-05\n","2.8258513e-05\n","2.7987184e-05\n"],"name":"stdout"}]},{"metadata":{"id":"LKad5CZ7-4qA","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}