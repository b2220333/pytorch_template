{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"two_layer_net_autograd.ipynb","version":"0.3.2","views":{},"default_view":{},"provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"5vlxrXD2QTlp","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# Install Pytorch.\n","from os import path\n","from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n","platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n","\n","accelerator = 'cu80' if path.exists('/opt/bin/nvidia-smi') else 'cpu'\n","\n","!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.3.0.post4-{platform}-linux_x86_64.whl torchvision"],"execution_count":0,"outputs":[]},{"metadata":{"id":"ovuByS4FQN3D","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["%matplotlib inline"],"execution_count":0,"outputs":[]},{"metadata":{"id":"CH18Mjo-QN3G","colab_type":"text"},"cell_type":"markdown","source":["\n","PyTorch: Variables and autograd\n","-------------------------------\n","\n","A fully-connected ReLU network with one hidden layer and no biases, trained to\n","predict y from x by minimizing squared Euclidean distance.\n","\n","This implementation computes the forward pass using operations on PyTorch\n","Variables, and uses PyTorch autograd to compute gradients.\n","\n","A PyTorch Variable is a wrapper around a PyTorch Tensor, and represents a node\n","in a computational graph. If x is a Variable then x.data is a Tensor giving its\n","value, and x.grad is another Variable holding the gradient of x with respect to\n","some scalar value.\n","\n","PyTorch Variables have the same API as PyTorch tensors: (almost) any operation\n","you can do on a Tensor you can also do on a Variable; the difference is that\n","autograd allows you to automatically compute gradients.\n","\n"]},{"metadata":{"id":"lijgAqrBQN3H","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"output_extras":[{"item_id":4}],"base_uri":"https://localhost:8080/","height":8517},"outputId":"0586848d-57fb-4cbc-8ae3-a1fa0384f155","executionInfo":{"status":"ok","timestamp":1522839307297,"user_tz":-480,"elapsed":4120,"user":{"displayName":"Ting-Hao Chen","photoUrl":"//lh5.googleusercontent.com/-AqNMIr4i_vY/AAAAAAAAAAI/AAAAAAACYZM/s73Q8MSTaOY/s50-c-k-no/photo.jpg","userId":"102252651198589151727"}}},"cell_type":"code","source":["import torch\n","from torch.autograd import Variable\n","\n","# dtype = torch.FloatTensor # Run on CPU\n","dtype = torch.cuda.FloatTensor\n","\n","# N: batch size, D_in: input dim, H: hidden dim, D_out: output dim\n","N, D_in, H, D_out = 64, 1000, 100, 10\n","\n","# Create random Tensors to hold input and outputs, and wrap them in Variables.\n","# Setting requires_grad=False indicates that we do not need to compute gradients\n","# with respect to these Variables during the backward pass.\n","x = Variable(torch.randn(N, D_in).type(dtype), requires_grad=False)\n","y = Variable(torch.randn(N, D_out).type(dtype), requires_grad=False)\n","\n","# Create random Tensors for weights, and wrap them in Variables.\n","# Setting requires_grad=True indicates that we want to compute gradients with\n","# respect to these Variables during the backward pass.\n","w1 = Variable(torch.randn(D_in, H).type(dtype), requires_grad=True)\n","w2 = Variable(torch.randn(H, D_out).type(dtype), requires_grad=True)\n","\n","learning_rate = 1e-6\n","\n","for t in range(500):\n","    # Forward pass: compute predicted y using operations on Variables; these\n","    # are exactly the same operations we used to compute the forward pass using\n","    # Tensors, but we do not need to keep references to intermediate values since\n","    # we are not implementing the backward pass by hand.\n","    y_pred = x.mm(w1).clamp(min=0).mm(w2)\n","    \n","    # Compute and print loss using operations on Variables.\n","    # Now loss is a Variable of shape (1,) and loss.data is a Tensor of shape\n","    # (1,); loss.data[0] is a scalar value holding the loss.\n","    loss = (y_pred - y).pow(2).sum()\n","    print(t, loss.data[0])\n","    \n","    # Use autograd to compute the backward pass. This call will compute the\n","    # gradient of loss with respect to all Variables with requires_grad=True.\n","    # After this call w1.grad and w2.grad will be Variables holding the gradient\n","    # of the loss with respect to w1 and w2 respectively.\n","    loss.backward()\n","\n","    # Update weights using gradient descent; w1.data and w2.data are Tensors,\n","    # w1.grad and w2.grad are Variables and w1.grad.data and w2.grad.data are\n","    # Tensors.\n","    w1.data -= learning_rate * w1.grad.data\n","    w2.data -= learning_rate * w2.grad.data\n","    \n","    # Manually zero the gradients after updating weights\n","    w1.grad.data.zero_()\n","    w2.grad.data.zero_()"],"execution_count":3,"outputs":[{"output_type":"stream","text":["0 38236308.0\n","1 39659528.0\n","2 47680172.0\n","3 51015928.0\n","4 39794716.0\n","5 21004940.0\n","6 8223178.5\n","7 3276394.5\n","8 1720325.75\n","9 1172659.25\n","10 911285.125\n","11 745672.4375\n","12 623506.625\n","13 527283.0\n","14 449427.9375\n","15 385316.625\n","16 332234.875\n","17 287976.0\n","18 250752.34375\n","19 219290.765625\n","20 192510.96875\n","21 169614.0625\n","22 149932.84375\n","23 132939.9375\n","24 118211.84375\n","25 105399.3984375\n","26 94225.4609375\n","27 84467.1953125\n","28 75906.4375\n","29 68362.375\n","30 61687.0703125\n","31 55771.546875\n","32 50509.44921875\n","33 45821.5\n","34 41633.74609375\n","35 37885.76171875\n","36 34523.6875\n","37 31502.4375\n","38 28781.84375\n","39 26327.982421875\n","40 24110.580078125\n","41 22103.658203125\n","42 20283.392578125\n","43 18632.65234375\n","44 17132.677734375\n","45 15768.724609375\n","46 14525.7138671875\n","47 13391.8232421875\n","48 12356.19921875\n","49 11406.3017578125\n","50 10537.2841796875\n","51 9741.0849609375\n","52 9010.8505859375\n","53 8340.783203125\n","54 7725.1083984375\n","55 7159.2705078125\n","56 6638.5849609375\n","57 6158.91943359375\n","58 5716.9169921875\n","59 5309.36279296875\n","60 4933.15576171875\n","61 4585.61767578125\n","62 4264.5625\n","63 3967.58203125\n","64 3692.788818359375\n","65 3438.455078125\n","66 3202.917724609375\n","67 2984.5634765625\n","68 2782.125\n","69 2594.463623046875\n","70 2420.28662109375\n","71 2258.5625\n","72 2108.3369140625\n","73 1968.7452392578125\n","74 1838.935546875\n","75 1718.215087890625\n","76 1605.895751953125\n","77 1501.3304443359375\n","78 1403.97509765625\n","79 1313.303466796875\n","80 1228.7760009765625\n","81 1150.0069580078125\n","82 1076.5643310546875\n","83 1008.0477905273438\n","84 944.1103515625\n","85 884.4427490234375\n","86 828.7520141601562\n","87 776.7455444335938\n","88 728.1475830078125\n","89 682.7583618164062\n","90 640.3475341796875\n","91 600.6824951171875\n","92 563.587646484375\n","93 528.8925170898438\n","94 496.43280029296875\n","95 466.0641784667969\n","96 437.6352233886719\n","97 411.0238342285156\n","98 386.1026306152344\n","99 362.75543212890625\n","100 340.8934326171875\n","101 320.4123840332031\n","102 301.21673583984375\n","103 283.2167663574219\n","104 266.3504333496094\n","105 250.5222930908203\n","106 235.67291259765625\n","107 221.74325561523438\n","108 208.67202758789062\n","109 196.3986053466797\n","110 184.87701416015625\n","111 174.0636749267578\n","112 163.9068145751953\n","113 154.36720275878906\n","114 145.39996337890625\n","115 136.97804260253906\n","116 129.057861328125\n","117 121.62055969238281\n","118 114.63187408447266\n","119 108.05755615234375\n","120 101.87326049804688\n","121 96.05532836914062\n","122 90.58365631103516\n","123 85.43619537353516\n","124 80.59369659423828\n","125 76.03257751464844\n","126 71.74346923828125\n","127 67.70222473144531\n","128 63.896728515625\n","129 60.31173324584961\n","130 56.93810272216797\n","131 53.759620666503906\n","132 50.76115417480469\n","133 47.93771743774414\n","134 45.27496337890625\n","135 42.7667350769043\n","136 40.40176773071289\n","137 38.17161178588867\n","138 36.06999206542969\n","139 34.0868034362793\n","140 32.21501922607422\n","141 30.450429916381836\n","142 28.78567123413086\n","143 27.2130126953125\n","144 25.732894897460938\n","145 24.332937240600586\n","146 23.012529373168945\n","147 21.765562057495117\n","148 20.587491989135742\n","149 19.475948333740234\n","150 18.426589965820312\n","151 17.4346866607666\n","152 16.49785614013672\n","153 15.612822532653809\n","154 14.776381492614746\n","155 13.98658561706543\n","156 13.240103721618652\n","157 12.534477233886719\n","158 11.86762809753418\n","159 11.23779010772705\n","160 10.641406059265137\n","161 10.078400611877441\n","162 9.54491138458252\n","163 9.041097640991211\n","164 8.56456470489502\n","165 8.113648414611816\n","166 7.687347412109375\n","167 7.283838272094727\n","168 6.902482509613037\n","169 6.540946960449219\n","170 6.199103355407715\n","171 5.875883102416992\n","172 5.570131778717041\n","173 5.280272006988525\n","174 5.006267070770264\n","175 4.747206687927246\n","176 4.501348495483398\n","177 4.268625259399414\n","178 4.048359394073486\n","179 3.8393609523773193\n","180 3.6416804790496826\n","181 3.4542877674102783\n","182 3.2770042419433594\n","183 3.1088340282440186\n","184 2.949993133544922\n","185 2.798771381378174\n","186 2.65592622756958\n","187 2.5204968452453613\n","188 2.391723871231079\n","189 2.2698936462402344\n","190 2.154622793197632\n","191 2.0449390411376953\n","192 1.9416228532791138\n","193 1.8431696891784668\n","194 1.7496284246444702\n","195 1.6612110137939453\n","196 1.5776712894439697\n","197 1.4979164600372314\n","198 1.4223731756210327\n","199 1.3504201173782349\n","200 1.2827781438827515\n","201 1.2182068824768066\n","202 1.1570559740066528\n","203 1.0990241765975952\n","204 1.043950080871582\n","205 0.9918224215507507\n","206 0.9421765804290771\n","207 0.8952345848083496\n","208 0.850553572177887\n","209 0.8081044554710388\n","210 0.7678494453430176\n","211 0.7295976877212524\n","212 0.6933426260948181\n","213 0.6589872241020203\n","214 0.6262599229812622\n","215 0.595390796661377\n","216 0.5658103227615356\n","217 0.5377794504165649\n","218 0.511199414730072\n","219 0.4859316051006317\n","220 0.4618249237537384\n","221 0.439049631357193\n","222 0.4175218939781189\n","223 0.3970091938972473\n","224 0.3774549961090088\n","225 0.3589915931224823\n","226 0.34135690331459045\n","227 0.32462581992149353\n","228 0.3086652159690857\n","229 0.2935543954372406\n","230 0.2791007459163666\n","231 0.26543354988098145\n","232 0.2524806261062622\n","233 0.2401128113269806\n","234 0.22840066254138947\n","235 0.21719300746917725\n","236 0.20665375888347626\n","237 0.19663774967193604\n","238 0.18702726066112518\n","239 0.17792470753192902\n","240 0.16932661831378937\n","241 0.1611437350511551\n","242 0.15329310297966003\n","243 0.14581042528152466\n","244 0.13883760571479797\n","245 0.13206742703914642\n","246 0.1256246417760849\n","247 0.11958501487970352\n","248 0.11374282836914062\n","249 0.10824055224657059\n","250 0.10300379246473312\n","251 0.0980464369058609\n","252 0.09331977367401123\n","253 0.08887260407209396\n","254 0.08456594496965408\n","255 0.0805247575044632\n","256 0.07664605230093002\n","257 0.07294315844774246\n","258 0.06940559297800064\n","259 0.06606973707675934\n","260 0.0629139244556427\n","261 0.059937380254268646\n","262 0.05701104924082756\n","263 0.054322272539138794\n","264 0.051722995936870575\n","265 0.04926356300711632\n","266 0.04687938094139099\n","267 0.04463442042469978\n","268 0.04248708859086037\n","269 0.040478404611349106\n","270 0.03856075927615166\n","271 0.036703504621982574\n","272 0.03496983274817467\n","273 0.03329908102750778\n","274 0.031728796660900116\n","275 0.030222924426198006\n","276 0.028797972947359085\n","277 0.02743844874203205\n","278 0.02612575888633728\n","279 0.024894429370760918\n","280 0.023735014721751213\n","281 0.02261626534163952\n","282 0.02154063992202282\n","283 0.02052105963230133\n","284 0.0195396039634943\n","285 0.01862797513604164\n","286 0.017754387110471725\n","287 0.016928574070334435\n","288 0.016130929812788963\n","289 0.015374272130429745\n","290 0.014650526456534863\n","291 0.013969622552394867\n","292 0.013324362225830555\n","293 0.012703853659331799\n","294 0.012101405300199986\n","295 0.011539488099515438\n","296 0.011010915040969849\n","297 0.010499343276023865\n","298 0.010017799213528633\n","299 0.009568069130182266\n","300 0.009128126315772533\n","301 0.008708694018423557\n","302 0.008307564072310925\n","303 0.007927539758384228\n","304 0.0075644683092832565\n","305 0.0072201271541416645\n","306 0.00688933115452528\n","307 0.00657699117437005\n","308 0.006280775647610426\n","309 0.006007332820445299\n","310 0.005727552808821201\n","311 0.005475340876728296\n","312 0.005223344080150127\n","313 0.004987018182873726\n","314 0.004771904554218054\n","315 0.0045598880387842655\n","316 0.004365675151348114\n","317 0.004173903726041317\n","318 0.003993419464677572\n","319 0.0038206700701266527\n","320 0.00365457427687943\n","321 0.003498052479699254\n","322 0.0033485451713204384\n","323 0.003204140579327941\n","324 0.003068269230425358\n","325 0.0029387956019490957\n","326 0.002814117819070816\n","327 0.0026999025139957666\n","328 0.0025897203013300896\n","329 0.0024837451055645943\n","330 0.002378561068326235\n","331 0.0022820699959993362\n","332 0.0021903924643993378\n","333 0.002100677229464054\n","334 0.0020140584092587233\n","335 0.0019328721100464463\n","336 0.00185488467104733\n","337 0.0017805220559239388\n","338 0.0017093945061787963\n","339 0.0016406973591074347\n","340 0.00157691549975425\n","341 0.0015163820935413241\n","342 0.001458197133615613\n","343 0.0014031310565769672\n","344 0.0013511201832443476\n","345 0.0013004973297938704\n","346 0.0012495664414018393\n","347 0.001203053630888462\n","348 0.0011613593669608235\n","349 0.0011164328316226602\n","350 0.001076182583346963\n","351 0.0010382896289229393\n","352 0.0010028914548456669\n","353 0.000967194268014282\n","354 0.0009312906768172979\n","355 0.0009000132558867335\n","356 0.0008692207629792392\n","357 0.0008395466720685363\n","358 0.0008104710141196847\n","359 0.0007829550886526704\n","360 0.0007568494183942676\n","361 0.0007319481810554862\n","362 0.0007065722602419555\n","363 0.0006842724396847188\n","364 0.000662459759041667\n","365 0.0006410069181583822\n","366 0.0006218408234417439\n","367 0.0006013602833263576\n","368 0.0005824124673381448\n","369 0.0005637318245135248\n","370 0.0005461731925606728\n","371 0.0005296709714457393\n","372 0.0005138158448971808\n","373 0.000497677712701261\n","374 0.00048328450066037476\n","375 0.00046942068729549646\n","376 0.00045606709318235517\n","377 0.00044205450103618205\n","378 0.0004301114531699568\n","379 0.0004180582473054528\n","380 0.00040537930908612907\n","381 0.00039297467446886003\n","382 0.0003826605388894677\n","383 0.00037260985118336976\n","384 0.00036211535916663706\n","385 0.0003530083631630987\n","386 0.0003424430324230343\n","387 0.0003330129839014262\n","388 0.0003244683030061424\n","389 0.0003160529595334083\n","390 0.0003084465570282191\n","391 0.00030011223861947656\n","392 0.0002924581349361688\n","393 0.00028434302657842636\n","394 0.0002779752539936453\n","395 0.0002707041858229786\n","396 0.00026368172257207334\n","397 0.0002566187467891723\n","398 0.00025126771652139723\n","399 0.0002442437980789691\n","400 0.00023802538635209203\n","401 0.00023288323427550495\n","402 0.0002271699922857806\n","403 0.00022167708084452897\n","404 0.00021657651814166456\n","405 0.0002115288225468248\n","406 0.00020665493502747267\n","407 0.00020179615239612758\n","408 0.0001974830374820158\n","409 0.00019247765885666013\n","410 0.0001885296223917976\n","411 0.00018401080160401762\n","412 0.00018025118333753198\n","413 0.0001765396009432152\n","414 0.0001725724432617426\n","415 0.0001693315280135721\n","416 0.0001658037508605048\n","417 0.00016268444596789777\n","418 0.00015899294521659613\n","419 0.00015578213788103312\n","420 0.00015220395289361477\n","421 0.00014907233708072454\n","422 0.00014575119712390006\n","423 0.00014296453446149826\n","424 0.00014009494043421\n","425 0.0001373781415168196\n","426 0.00013489043340086937\n","427 0.0001322660391451791\n","428 0.00012950939708389342\n","429 0.00012725681881420314\n","430 0.0001246923056896776\n","431 0.00012207819963805377\n","432 0.00011974162771366537\n","433 0.00011763178190449253\n","434 0.00011442695540608838\n","435 0.00011223182082176208\n","436 0.00011029808956664056\n","437 0.00010875288717215881\n","438 0.00010657335224095732\n","439 0.00010474817099748179\n","440 0.00010295047104591504\n","441 0.00010092179581988603\n","442 9.928750660037622e-05\n","443 9.747482545208186e-05\n","444 9.582703933119774e-05\n","445 9.430512727703899e-05\n","446 9.25171552808024e-05\n","447 9.1003421403002e-05\n","448 8.953637006925419e-05\n","449 8.818517380859703e-05\n","450 8.675386925460771e-05\n","451 8.557815453968942e-05\n","452 8.4253704699222e-05\n","453 8.259472815552726e-05\n","454 8.124813757603988e-05\n","455 8.004690607776865e-05\n","456 7.843884668545797e-05\n","457 7.728619675617665e-05\n","458 7.60821858420968e-05\n","459 7.455980812665075e-05\n","460 7.356898277066648e-05\n","461 7.241441198857501e-05\n","462 7.117252243915573e-05\n","463 6.975625001359731e-05\n","464 6.896154809510335e-05\n","465 6.785957521060482e-05\n","466 6.689858855679631e-05\n","467 6.588464020751417e-05\n","468 6.500926247099414e-05\n","469 6.406081229215488e-05\n","470 6.325076537905261e-05\n","471 6.226696132216603e-05\n","472 6.141599442344159e-05\n","473 6.048447539797053e-05\n","474 5.9810492530232295e-05\n","475 5.874755515833385e-05\n","476 5.7816057960735634e-05\n","477 5.705273724743165e-05\n","478 5.638842048938386e-05\n","479 5.575748218689114e-05\n","480 5.517571116797626e-05\n","481 5.430559394881129e-05\n","482 5.381718438002281e-05\n","483 5.293056892696768e-05\n","484 5.221220635576174e-05\n","485 5.162777961231768e-05\n","486 5.09582350787241e-05\n","487 5.0457092584110796e-05\n","488 5.001625686418265e-05\n","489 4.931058720103465e-05\n","490 4.8636622523190454e-05\n","491 4.8228728701360524e-05\n","492 4.7678393457317725e-05\n","493 4.7098314098548144e-05\n","494 4.649289621738717e-05\n","495 4.581333996611647e-05\n","496 4.5436390792019665e-05\n","497 4.495949178817682e-05\n","498 4.43775970779825e-05\n","499 4.374455238576047e-05\n"],"name":"stdout"}]},{"metadata":{"id":"9U92piJjS7Ol","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}